

# SQL 레벨업



1장 DBMS 아키텍처



2장 SQL 기초



3장 SQL의 조건 분기



4장 집약과 자르기



5장 반복문



6장 결합



7장 서브쿼리



8장 SQL의 순서



9장 갱신과 데이터 모델



10장 인덱스 사용







# 1장 DBMS 아키텍처

![image-20230201180033073](/Users/ysk/study/study_repo/postgresql/images//image-20230201180033073.png)

일반적인 DBMS 아키텍처는 위와 같은 구조를 가지고 있다.
DBMS 내부의 기능을 알아보자.

### 쿼리 평가 엔진

- 사용자로부터 입력받은 SQL 구문을 분석, **실행 계획**(Explain Plan, 어떤 순서로 데이터에 접근하는지)을 결정한다.
- 실행 계획을 기반으로 데이터에 접근하는 방법을 **접근 메서드**(Access Method)라고 한다.



> 쿼리 평가 엔진 = 계획을 세우고 실행하는 DBMS의 핵심 기능을 담당하는 모듈

### 버퍼 매니저

- DBMS는 **버퍼**라는 메모리 영역을 확보하는데, 이를 관리한다.
- 디스크를 관리하는 디스크 용량 매니저와 연동되어 작동한다.

### 디스크 용량 매니저

- 데이터를 어디에 어떻게 저장할지 관리한다.
- 데이터의 I/O를 제어한다.
- 데이터베이스는 데이터를 영구적으로 저장해야 하므로 디스크 용량 매니저가 어디에 어떻게 데이터를 저장할지 관리하고, 읽고 쓰기를 제어한다.

### 트랜잭션 매니저와 락 매니저

- DBMS에서 각각의 처리는 DBMS 내부에서 트랜잭션이라는 단위로 관리되는데, 이를 정합성(무모순성)을 유지하면서 실행시킨다.
- 필요한 경우 데이터에 락을 절어 다른 사람의 요청을 대기시킨다.

### 리커버리 매니저

- 시스템의 장애를 대비한다.
- 데이터를 정기적으로 백업하고, 문제가 일어났을 때 데이터를 복구한다.



## 2. DBMS와 버퍼

메모리는 한정된 희소 자원인 반면에 데이터는 굉장히 많기 때문에 버퍼에 어떤 식으로 확보할 것인가 하는 부분에서 트레이드오프가 발생한다.
DBMS는 대부분 용량, 비용, 성능의 관점에서 HDD를 사용한다.
***성능 향상을 위해 자주 참조되는 데이터를 메모리 위에 올려둔다***.
-> 성능 향상을 목적으로 데이터를 저장하는 메모리를 버퍼(buffer), 캐시(cache)라고 부른다.

> 버퍼에 어떻게, 어느 정도의 기간 동안 올릴지를 관리하는 것이 버퍼 매니저이다.

![image-20230201180813064](/Users/ysk/study/study_repo/postgresql/images//image-20230201180813064.png)

기억장치의 분류를 계층으로 나타낸 그림이다.
여기서 기억비용은 데이터를 저장하는데 소모되는 비용을 말한다.



DBMS는 데이터 저장을 목적으로 하는 미들웨어이다.

#### HDD, SDD

- 현재 DBMS는 데이터를 HDD 또는 SSD에 저장한다.

#### 메모리

- 디스크에 비해 기억비용이 비싸다. (대충 수십만~수백만 배 차이)
- 따라서 DB의 내부 데이터를 모두 올려놓는 것은 불가능하다.

#### 버퍼를 활용한 속도 향상

- 그럼에도 메모리를 사용하는 이유는 성능 향상 떄문이다.
- 일반적인 SQL 구문의 실행 시간 대부분을 I/O에 사용한다.
- 따라서, 자주 접근하는 데이터를 메모리 위에 올려놓으면 성능이 무척 향상된다.

![image-20230201181038212](/Users/ysk/study/study_repo/postgresql/images//image-20230201181038212.png)

* 같은 SQL 구문을 실행한다고 해도 디스크에서 데이터를 가져올 필요 없이 곧바로 메모리에서 읽어 빠르게 데이터를 검색하는것이 더 좋다.
* 디스크의 접근을 줄일 수 있다면 큰 폭의 성능 향상이 가능하다. 
* 일반적인 SQL 구문의 실행 시간 대부분을 저장소 I/O에 사용하기 때문 



이렇게 성능 향상을 목적으로 데이터를 저장하는 메모리를 버퍼 또는 캐시라고 부른다.



> 버퍼에 데이터를 어떻게, 어느정도의 기간 동안 올릴지를 관리하는 것이 버퍼 매니저이다.



### 메모리 위의 두 버퍼

DBMS가 사용하는 버퍼는 크게 두 종류다.

- 데이터 캐시
- 로그 버퍼
  이러한 버퍼는 사용자가 용도에 따라 크기를 변경할 수 있다.



#### 데이터 캐시

- 디스크에 있는 데이터의 일부를 메모리에 유지하기 위해 사용하는 메모리 영역이다.
- 데이터 캐시에 필요로 하는 SQL 구문의 데이터가 전부 있다면 디스크를 접근하지 않고 처리를 수행한다.

#### 로그 버퍼

- 로그 버퍼는 갱신처리(INSERT, DELETE, UPDATE, MERGE)와 관련있다.
- 갱신처리가 이루어지는 과정
  - 갱신과 관련된 SQL 구문을 받으면 로그 버퍼에 변정 정보를 보낸다.
  - 이후 디스크에 변경을 비동기적으로 수행한다.
- 갱신처리는 시간소요가 많이 되기에 이처럼 수행된다.

> 곧바로 저장소에 있는 데이터를 변경하지 않고, 로그 버퍼 위에 변경 정보를 보내고 이후에 디스크 내용 수정

![image-20230201181440375](/Users/ysk/study/study_repo/postgresql/images//image-20230201181440375.png)

* 갱신 처리는 비동기로 이루어진다

**갱신 처리는 SQL 실행 시점과 저장소에 갱신하는 시점에 차이가 있는 비동기 처리이다.**

* 갱신 시 상당한 시간이 소모되므로 갱신 정보를 받은 시점에 로그를 쌓고, 내부적으로 관련된 처리를 수행한다.



### 메모리의 성질이 초래하는 트레이드 오프

메모리의 휘발성때문에 로그 버퍼의 데이터가 DBMS가 다운될 때 사라지는 현상이 생길 수 있다.

로그 버퍼 위의 데이터가 디스크에 저장되기 전 사라저버리면 복구가 불가능하다.
이는 비즈니스적인 관점에서 심각한 문제이다.

이를 회피하기 위해 커밋 시점에 갱신정보를 로그 파일(영속적인 저장소에 존재함)에 작성해 정합성을 지키고자 한다.

이 때문에 새로운 트레이드 오프가 발생하는데, `커밋 시에는 디스크에 동기 접속이 일어난다.`

* (일부 DBMS는 설정으로 비동기 접속으로 변환 가능하지만... 극단적인 트레이드오프이다.)

* 커밋은 갱신 처리를 확정하는것. DBMS는 커밋된 데이터를 영속화 한다. -> 동기 접속 발생



> - 비동기 처리시 : 데이터 정합성 ↓, 성능 ↑
> - 동기 처리시 : 데이터 정합성 ↑, 성능 ↓



### 시스템 특성에 따른 트레이드 오프

![image-20230201181906527](/Users/ysk/study/study_repo/postgresql/images//image-20230201181906527.png)

#### 데이터 캐시와 로그 버퍼의 크기

DBMS에서 제공하는 데이터 캐시에 비해 로그 버퍼의 초깃값이 굉장히 작다.
-> 데이터베이스는 기본적으로 검색을 메인으로 처리한다고 가정하기 때문이다.

* 실제로도 많은 DBMS가 물리 메모리에 여유가 있다면 데이터 캐시를 되도록 많이 할당하라고 권장한다.
  (MySQL 5.7 공식문서에서도 DB전용 서버에서는 물리 메모리의 80%를 버퍼 풀이 차지해도 괜찮다고 쓰여있다.)

* 로그 버퍼는 갱신처리에 쌓이고, 갱신처리는 검색(조회)처리보다 규모가 적다.

검색 시에 레코드가 수천만 건에 달하는 경우도 있지만, 갱신 처리는 많아봤자 수만 건 정도밖에 안된다.

> 갱신 처리에 값비싼 메모리를 많이 사용하는 것보다는, 자주 검색하는 데이터를 캐시에 올려놓는 것이 더 좋은 성능을 낼 수 있다.

검색에 비해 갱신이 많다면, 로그의 버퍼의 크기를 늘려주는 성능 튜닝(최적화)가 필요하다 



### 메모리 크기를 트레이드오프 하자

자신의 시스템에 검색보다 업데이트가 많다 : 데이터 캐시 < 로그버퍼 더 크게 잡기
업데이트보다 검색이 많다 : 데이터 캐시를 더 크게 잡기 > 로그 버퍼



## 추가적인 메모리 영역 '워킹 메모리'

#### 워킹 메모리란?

- DBMS는 일반적으로 2개의 버퍼 외에 워킹 메모리라는 영역을 가지고 있다.
- 이는 정렬(일반적으로 ORDER BY), 해시(테이블 조인) 관련 처리에 사용되는 작업용 영역이다.
- 가변적인 용량을 가지고 정렬, 해시가 필요할 때 사용되고, 종료하면 해제되는 임시 영역이다.
- 여러개의 SQL 구문들이 나눠서 사용하므로 동시에 실행하면 메모리의 범위를 넘어가는 일이 생기기도 한다.



**워킹 메모리를 부르는 명칭**

| DBMS           | 명칭                     | 매개변수             | 기본값                         |
| -------------- | ------------------------ | -------------------- | ------------------------------ |
| Oracle 11g R2  | PGA(Program Global Area) | PGA_AGGREGAGE_TARGET | 10MB or SGA크기의 20% 중 큰 것 |
| PostgreSQL 9.3 | 워크 버퍼                | work_mem             | 8MB                            |
| MySQL 5.7      | 정렬 버펴                | sort_buffer_size     | 256kb                          |

#### 워킹 메모리가 부족하다면?

워킹 메모리가 다루려는 데이터보다 양이 부족하다면 디스크를 사용한다. 즉, 처리가 굉장히 느려지게 된다.

![image-20230201183442690](/Users/ysk/study/study_repo/postgresql/images//image-20230201183442690.png)

##### 워킹 메모리가 부족할 때 사용하는 임시적인 영역

- Oracle : 임시 테이블 스페이스(TEMP Tablespace)
- Microsoft SQL Server : TEMPDB
- PostgreSQL : 일시 영역(pgsql_tmp)



> 데이터베이스는 메모리가 부족하다는 이유로 SQL 구문에 오류를 절대 발생 시키지 않고 느려지더라도 끝까지 처리하려 노력한다.



## 3. DBMS와 실행 계획

성능 문제 등 내부 절차를 확인해야 할 때 실행계획을 사용한다.



### DBMS의 쿼리 처리 흐름

![image-20230201183656818](/Users/ysk/study/study_repo/postgresql/images//image-20230201183656818.png)

#### 1. 파서 (parser) : 사용자로부터 SQL구문이 올바른지 검사한다.

#### 2. 옵티마이저 (optimizer, 최적화)

- 인덱스 유무, 데이터 분산 또는 편향도, 매개변수 등의 조건을 고려해 **선택 가능한 많은 실행 계획을 작성**한다.
- 많은 실행 계획들의 비용을 계산하여 가장 낮은 비용을 가진 실행 계획을 선택한다. 

#### 3. 카탈로그 매니저 (catalog manager)

* 옵티마이저가 비용을 계산하는데 도움을 준다.
* DBMS의 내부 정보(카탈로그)를 모아놓은 테이블로, 테이블 또는 인덱스의 통계 정보가 저장되어 있다. -> '통계 정보' 라 칭한다.

#### 4. 플랜 평가 (plan evaluation)

* 옵티마이저가 여러 개의 실행 계획을 세운 뒤 그것을 받아 **최적의 실행 결과를 선택**한다.

* 이는 사람이 쉽게 읽을 수 있도록 작성 된 일종의 '계획서'이다.
* 실행계획이 선택되면 실행계획을 절차적인 코드로 변환하고 데이터 접근을 수행한다.

**주의**
플랜 선택을 옵티마이저에게 맡길 경우, 최적의 플랜이 선택되지 않을 수 있다.
대표적 이유 : 통계 정보 부족 (카탈로그 매니저)
-> 데이터의 수정이 일어났을 때 카탈로그 정보가 갱신되지 않아 과거의 정보로 선택할 수 있다.

> 테이블의 데이터가 많이 바뀌면 카탈로그의 정보도 업데이트 해야 하는 것이 상식이다. ( 업데이트 실행 비용이 많이 든다. )



### 옵티마이저와 통계 정보

옵티마이저가 효율적인 플랜을 선택하지 않는 경우가 있는데, 주로 통계 정보가 부족해서다.

구현에 따라 차이는 있찌만 카탈로그에 포함되어 있는 통계 정보는 다음과 같다.

#### 카탈로그에 포함되는 정보

- 테이블의 레코드(row) 수
- 테이블의 필드 수와 필드 크기
- 필드의 카디널리티(값의 중복되는 개수)
- 필드 값의 히스토그램(어떤 값이 분포되어 있는가)
- 필드 내부의 NULL 수
- 인덱스 정보

이러한 정보를 사용해 카탈로그를 만들고 이를 기반으로 옵티마이저가 계획을 세우게 된다.
실제 테이블에 변화가 일어나도 카탈로그를 갱신하지 않으면 옵티마이저는 갱신되지 않은 카탈로그를 기준으로 계획을 세우기 때문에 잘못된 계획을 세우게 될 수 있다.

올바른 통계 정보가 모이는 것은 SQL 성능에 중요한 문제이다.
따라서 테이블의 데이터가 많이 변하면 카탈로그의 통계 정보도 함께 갱신해야 한다.



> 통계 정보 갱신은 많은 시간을 소요하는 작업이므로 갱신 시점을 잘 설계해야 한다.



#### 대표적인 DBMS의 통계 정보 갱신 명령어

| 이름       | 명령어                                                       |
| ---------- | ------------------------------------------------------------ |
| Oracle     | exec DBMS STATS.GATHER_TABLE_STATS(OWNNAME<br />=> [스키마 이름], TABNAME => [테이블 이름)); |
| SQL Server | UPDATE STATISTICS [테이블 이름]                              |
| DB2        | RUNSTATS ON TABLE [스키마 이름].[테이블 이름];               |
| PostgreSQL | ANALYZE [스키마 이름].[테이블 이름];                         |
| MySQL      | ANALYZE TABLE [스키마 이름].[테이블 이름];                   |



## 4. 실행 계획이 SQL 구문의 성능을 결정



### 1. 실행 계획 확인 방법

| 이름                 | 명령어                                 |
| -------------------- | -------------------------------------- |
| Oracle               | set autotrace traceonly                |
| Microsoft SQL Server | SET SHOWPLAN TEXT ON                   |
| DB2                  | EXPLAIN ALL WITH SNAPSHOT FOR SQL 구문 |
| PostgreSQL           | EXPLAIN SQL 구문                       |
| MySQL                | EXPLAIN EXTENDED SQL 구문              |



실행계획의 시간복잡도

- 테이블 풀 스캔(Full Scan) : O(n)
- 인덱스 스캔 : O(log n)



### 테이블 풀 스캔의 실행 계획

```sql
select * from shops
```

```
|Id| Operation        | Name  | Rows | Bytes| Cost (%CPU) | Time
------------------------------------------------------------
|0| SELECT STATEMENT  |       |  60  | 1260 | 3 (0) | 00:00:01 Time
|1| TABLE ACCESS FULL | SHOPS |  60  | 1260 | 3 (0) | 00:00:01 Time
```





#### 실행 계획 해석

실행 계획의 출력 포맷은 DBMS에 따라 다르지만 공통적으로 포함하는 값이 있다.

1. `조작 대상 객체`
   - 어떤 객체(테이블)를 조작하는지 알려준다.
2. `객체에 대한 조작의 종류`
   - Oracle의 "TABLE ACCESS FULL", PostgreSQL의 "Seq Scan"
3. `조작 대상이 되는 레토드 수`
   - 어느정도의 레코드가 처리되는지 알려준다.
   - SQL 구문 전체의 실행 비용을 파악하는데 중요한 지표가 된다.



### 인덱스 스캔의 실행 계획

인덱스 스캔시, 키의 수 만큼 row를 조회한다.

Operation도 INDEX SCAN 이란 비슷한 단어들로 변화된다.



### 테이블 결합(Join)의 실행 계획

**결합의 실행 계획 알고리즘**

1. Nested Loops (중첩 반복)
   한쪽 테이블을 읽으며 레코드 하나마다 결합 조건에 맞는 레코드를 다른 쪽 테이블에서 찾는 방식 -> 이중 for문
2. Sort Merge
   결합 키로 레코드를 정렬한 뒤, 순차적으로 두 개의 테이블을 결합하는 방법
   결합 전에 전처리로 정렬을 수행해야 한다 -> 워킹 메모리 사용
3. Hash
   해시 테이블을 만듦 -> 작업용 메모리 영역 필요

Oracle : NESTED LOOPS
PostgerSQL : NESTED LOOPS

실행 계획은 일반적으로 트리 구조이다. 중첩 단계가 깊을수록 먼저 실행된다.

옵티마이저가 완벽하지 않기 때문에 Hint 구를 사용해 최적의 선택을 할 수 있게 수동으로 조절할 수 있다.

#### 실행 계획의 실행 비용과 실행 시간

실행 계획에서 표시하는 시간이나 조작 레코드 수는 어디까지나 추정 값일 뿐 지표로 사용할 수 없다.
다만, 일부 DBMS는 구문을 실행해서 실제 시간과 실제 조작 레코드 수를 표시하는 기능을 지원한다.



### 5. 실행 계획의 중요성

최근의 옵티마이저는 우수하지만 완벽하지 않다.
실행 계획이 잘못 설계되었다고 판단되는 경우, 튜닝을 한다. (수동으로 실행 계획 조작)
사실 실행 계획을 본다던가, 변경하는 것은 물리계층을 은폐한다는 RDB의 목표와 반대되는 일이지만 기술이 완벽하지 않은 지금은 필요한 일이다.



- DB는 다양한 트레이드 오프의 균형을 잡는 미들웨어
- 데이터를 디스크와 메모리 중 어디 위치 시킬 지 트레이드 오프가 중요



# 2장 SQL 기초

### ELECT 구와 FROM 구

검색을 위해 사용하는 SQL 구문을 SELECT 구문이라고 한다.

기본적으로 SELECT 구와 FROM 구로 이루어저 있다.

여기서 SQL의 특징을 알 수 있는데 데이터를 '어떤 방법으로' 선택할지 쓰여있지 않다는 것이다.
어떤 데이터가 필요한지 정하기만 하면 DBMS가 프로그래밍에서 절차 지향 같은 부분은 알아서 처리해준다.

### WHERE 구

WHERE 구를 사용해 추가적인 조건을 지정한다.

- WHERE 구에서 사용하는 연산자 (생략)

NULL은 데이터 값이 아니므로, 데이터에 사용하는 연산자(=)를 사용할 수 없다.

SELECT 구문은 절차 지향형 언어의 함수와 동일한 역할을 한다.
SELECT 구문의 입력과 출력 자료형은 **테이블** 뿐이다. 이러한 성질 때문에 폐쇄성(closure property, 관계가 닫혀있다는 의미)을 띈다고 부른다.

### GROUP BY 구

GROUP BY 구를 사용해 합계, 평균과 같은 집계 연산을 수행한다.

GROUP BY 구문을 사용해 여러 **그룹**을 만들고 숫자 관련 함수를 이용해 집계한다.

- GROUP BY 구에서 사용하는 집계함수 (생략)
  GROUP BY 구는 "GROUP BY ()"(생략 가능)를 이용해 테이블 전부를 하나의 그룹으로 만들 수 있다.

### HAVING 구

GROUP BY를 이용해 구한 그룹에 조건을 건다.

WHERE 구는 '레코드'에 HAVING 구는 '집합'에 조건을 지정한다.

### ORDER BY 구

명시적으로 순서를 정할 때 ORDER BY 구를 사용한다.

ASC(ascending order, 오름차순), DESC(descending order, 내림차순)을 키워드로 사용해 차순을 정한다. (명시하지 않으면 ASC)

### 뷰(View)

SELECT 구문을 DB에 저장하는 것을 **뷰**(View)라고 한다.

다만 테이블과 달리 내부에 데이터를 저장하지 않는다. 뷰는 어디까지나` 'SELECT 구문'을 저장`한 것이다.
따라서 SELECT 구문의 FROM 구에 뷰가 있다면 내부적으론 SELECT 구문이 중첩(nested)된 상태이다.

### 서브쿼리

SELECT 구문의 FROM 구에 직접 지정하는 SELECT 구문을 **서브쿼리**(subquery)라고 부른다.

IN 내부에서 서브쿼리를 사용하면 데이터가 변경되어도 따로 수정할 필요가 없다는 점에서 효율적이다.



## 7. 조건 분기, 집합 연산, 윈도우 함수, 갱신

### SQL과 조건 분기

일반적인 절차 지향형 프로그래밍 언어에는 if, switch 조건문 등이 있다.

SQL은 프로그래밍 언어와 달리 절차적으로 기술하지 않기 때문에 '문장'이 아닌 '식'을 기준으로 조건 분기를 정한다.
SQL에서 조건 분기를 실현하는 기능이 **CASE 식**이다.

CASE 식은 절차 지향의 switch 문과 거의 동일한 방식으로 작동한다.

CASE 식의 강점은 '식'이라는 것이다. 따라서 SELECT, WHERE, GROUP BY, HAVING, ORDER BY 구와 같은 곳 어디에나 작성할 수 있다.

```sql
CASE WHEN [평가식] THEN [식]
		 WHEN [평가식] THEN [식]
		 ...
		 ELSE [식]
END
```



### SQL의 집합 연산

SQL에는 테이블을 활용해 집합 연산을 할 수 있다.

#### UNION

UNION을 이용해 테이블 간 `합집합`을 구할 수 있다.
UNION은 합집합을 구할 때 중복을 제거한다. (INTERSECT, EXCEPT도 동일함)

UNION ALL을 이용하면 중복을 제외하지 않는다.

```sql
SELECT *
	FROM Address
UNION
SELECT *
	FROM Address2
```



#### INTERSECT

INTERSECT를 이용해 테이블 간 `교집합`을 구할 수 있다.

```sql
SELECT *
	FROM Address
INTERSECT
SELECT *
	FROM Address2
```

#### EXCEPT

EXCEPT를 이용해 테이블 간 `차집합`을 구할 수 있다.

UNION, INTERSECT와 달리 테이블의 순서에 따라 결과가 달라진다.

```sql
SELECT *
	FROM Address
EXCEPT
SELECT *
	FROM Address2
```

> Address - Address2



### 윈도우 함수

'집약 기능이 없는 GROUP BY 구'이다. GROUP BY 구는 자르기(개인적으로는 나누기라는 표현을 좋아함)와 집약이라는 2개의 기능을 가진다.

기본적인 구문은 집약 함수 뒤에 OVER 구를 작성하고 `PARTITION BY` 혹은 `ORDER BY` 구를 입력하는 것이다.

```sql
# 주소별 숫자
SELECT Address
	COUNT(*) OVER(PARTITION BY Adress)
	FROM Address
```



```sql
# 나이별 순위
SELECT Address
	RANK() OVER(PARTITION BY Adress)
	FROM Address
```

> 건너뛰는 작업 없이 순위를 구하고 싶다면 DENSE_RANK() 사용



### 트랜잭션과 갱신

위에서 말했듯이 DB는 검색 기능이 주가 되는 만큼 SQL의 검색 기능은 복잡하지만 반대로 SQL의 갱신 기능은 간단하다.

기본적으로 SQL의 갱신 작업은 아래와 같이 분류한다.

1. 삽입(insert)
2. 제거(delete)
3. 갱신(update)

1과 3을 합친 MERGE라는 기능도 있지만 일반적으로는 3가지로 분류한다.



# 3장 SQL의 조건 분기

> 식'을 바탕으로 하는 SQL에서 '구문'을 바탕으로 하는 절차 지향형 사고를 사용하면 생기는 문제점



## 쓸데없는 UNION의 사용

UNION은 외부적으로 하나의 SQL 구문을 실행하는 것처럼 보이지만, 내부적으로는 여러 개의 SELECT 구문을 실행하는 실행 계획으로 해석된다. 따라서 I/O 비용이 크게 증가한다.
UNION을 사용해도 좋을지 여부는 신중히 검토해야한다.

> 외부적으로는 하나의 SQL 구문을 사용하는 것처럼 보이지만 실제로는 여러 개의 구문이 실행하는 실행 계획으로 해석되기 때문이다.





다음과 같은 쿼리가 있다고 가정해보자.

```sql
SELECT item_name, year, price_tax_ex AS price
	FROM Items
 WHERE year <= 2001
UNION ALL
SELECT item_name, year, price_tax_ex AS price
	FROM Items
 WHERE year >= 2002;
```

거의 같은 쿼리를 두 번이나 실행하고 있다는 점도 문제지만, 성능적으로 문제가 된다.
UNION을 사용 했을 때의 실행 계획에서 **Item 테이블에 2회 접근**한다.
-> TABLE ACCESS FULL(index없이 테이블을 모두 스캔하는 것)도 2번 발생한다. ***읽어오는 비용도 테이블의 크기에 따라 선형적으로 증가하게 된다.***

UNION은 간단하게 레코드를 합칠 수 있다는 점에서 편리하지만, 물리 자원과 SQL의 성능을 나쁘게 만드므로 정확한 판단 하에 사용해야 한다.

#### 개선된 쿼리

```sql
SELECT item_name, year,
	CASE WHEN year <= 2001 THEN price_tax_ex
    	 WHEN year >= 2002 THEN price_tax_in END AS price
 FROM Items;
```

UNION을 사용한 쿼리와 같은 결과를 출력하지만 성능적으로 CASE를 쓴 쿼리가 훨씬 좋다.
Items 테이블 접근 횟수 : 1회
TABLE ACCESS FULL : 1회
**-> UNION을 사용한 구문보다 성능이 2배 좋아짐\**

UNION의 기본 단위는 SELECT '구문'이다. 이는 아직 절차 지향형의 발상을 벗어나지 못한 방법이다. 

반면, CASE의 기본 단위는 '식'이다.

> ***'구문'에서 '식'으로 사고를 변경하는 것이 SQL을 마스터하는 열쇠 중 하나이다.***





## UNION이 필요한 경우

### UNION을 사용할 수 밖에 없는 경우

머지 대상이 되는 SELECT 구문에서 사용하는 `테이블이 다른 경우`에는 UNION을 사용한다.

```sql
SELECT com_1
	FROM Table_A
 WHERE col_2 = 'A'
UNION ALL
SELECT col_3
	FROM Table_B
 WHERE col_4= 'B';
```

CASE 식을 사용할 수 없는 건 아니지만 이 경우 필요없는 결합이 발생해 성능적으로 악영향이 발생.

따라서 실행 계획을 확인해서 어떤 것이 더 좋은지 확인해야 한다.



### UNION이 성능이 더 좋은 경우

UNION을 사용했을 때 좋은 인덱스(압축을 잘 하는 인덱스)를 사용하지만, 이외의 경우에는 테이블 풀 스캔이 발생한다면, UNION을 사용한 방법이 성능적으로 더 좋을 수 있다.

이러한 경우 N회의 인덱스 스캔 VS 1회의 테이블 풀 스캔 중에서 어느 것이 더 빠른지에 대한 문제가 된다.
이 경우 테이블이 크고, 선택되는 레코드의 수가 적다면 UNION이 더 빠르다.

**예제 테이블**

| key  | name | date_1     | flg_1 | date_2     | flg_2 | date_3     | flg_3 |
| ---- | ---- | ---------- | ----- | ---------- | ----- | ---------- | ----- |
| 1    | a    | 2013-11-01 | T     |            |       |            |       |
| 2    | b    |            |       | 2013-11-01 | T     |            |       |
| 3    | c    |            |       | 2013-11-01 | F     |            |       |
| 4    | d    |            |       | 2013-12-30 | T     |            |       |
| 5    | e    |            |       |            |       | 2013-11-01 | T     |
| 6    | f    |            |       |            |       | 2013-12-01 | F     |

* 빈 값은 모두 NULL

```null
CREATE INDEX IDX_1 ON ThreeElements (date_1, flg_1);
CREATE INDEX IDX_2 ON ThreeElements (date_2, flg_2);
CREATE INDEX IDX_3 ON ThreeElements (date_3, flg_3);
```

이러한 인덱스를 만들어 테이블의 풀스캔보다 훨씬 빠른 접근 속도를 기대할 수 있다고 한다.



요점은 다음과 같다. OR, IN, CASE를 활용했을 경우 1회의 테이블 풀 스캔이 일어난다.

> 3회의 인덱스 스캔 VS 1회의 테이블 풀 스캔 중에 어떤 것이 빠른지 트레이드오프 해야한다.

테이블의 크기와 검색 조건에 따른 선택 비율에 따라 답이 달라진다.
테이블이 크고, WHERE 조건으로 선택되는 레코드의 수가 충분히 작다면 UNION이 더 빠르다.



다음 테이블에서 date가 2013-11-01이고, flg가 T인 레코드들만 추출하고 싶다.



## 절차 지향형과 선언형

### 구문 기반과 식 기반

원래 UNION은 조건 분기를 위해 만들어지지 않았으므로 조건 분기를 위해 만들어진 CASE 식과 비교하면 비효율적인 것이 당연한 결과다.

그럼에도 초보자들이 UNION을 사용해 조건 분기를 하는 이유는 절차 지향형 언어에 익숙해져 있기 때문이다. 하지만 SQL의 기본적인 체계는 선언형이다.

절차 지향형 프로그래밍 언어에서 생각의 기본 단위는 '구문'이다. 하지만 SQL에서의 기본 단위는 '식'이다. 실제로 SQL 구문의 각 부분(SELECT, FROM, WHERE, GROUP BY, ...)에 작성하는 것은 모두 '식'이다.

SQL 능력을 향상시키기 위해선 `선언형`에 익숙해저야 한다.



> 구문 에서 식으로 



# 4장 집약과 자르기

> 집합 지향(set-oriented) - 레코드 단위가 아닌 '집합' 단위로 처리를 기술하는 방식 
>
> **집합 지향**의 특징이 가장 잘 드러나는 상황은 GROUP BY 구, HAVING 구와 SUM, COUNT와 같은 집약 함수를 사용할 때다. 



### 집약 함수 (aggregate function)

집약 함수의 종류에는 다음 5가지 종류가 있다.
5가지에 대한 설명은 다들 알 것이라고 생각하고 생략하겠다.

- COUNT
- SUM
- AVG
- MAX
- MIN

### GROUP BY의 실행 계획

GROUP BY를 사용해 집약을 수행할 경우에 **정렬보다 해시 알고리즘**을 많이 사용한다.
경우에 따라서 정렬을 사용하기도 하지만, 보다 빠른 방법인 해시를 많이 사용한다.
해시의 성질상 GROUP BY의 유일성이 높으면 더 효율적으로 작동한다.

충분한 해시용(or 정렬용) 워킹 메모리가 확보되지 않으면 ***스왑***이 발생한다.
=> 저장소 위의 파일이 사용되면서 굉장히 느려짐



Oracle에서는 정렬과 해시를 위해 ***PGA***라는 메모리 영역을 사용하고, 집약 대상 데이터양에 비해 부족하면, 일시 영역(저장소)를 사용해 부족한 만큼 채운다.

> 이런 현상을 **'TEMP 탈락'**이라고 한다.

스왑이 일어나면 저장소에 TEMP(임시 영역)을 사용하는데 TEMP까지 부족해지면 SQL 구문이 비정상적으로 종료된다.

### PARTITION BY

GROUP BY 구에서 집약 기능을 제외하고 자르는 기능만 남긴 것이 윈도우 함수의 'PARTITION BY' 구이다.

PATITION BY 구는 자르기 부분에서는 GROUP BY와 별다른 부분 없이 동작한다.



# 5장 반복문

5장 요약

> SQL에서 함부로 반복문을 사용하지 마라.



**RDB에는 반복문이 없다. 이는 SQL에서 반복문이 없는 게 좋다고 판단했기 때문이다.**

> Orcal에서는 내부적으로 CASCADE DELETE 또는 CASCADE UPDATE에서 반복문이 사용된다.
>
> 부모 테이블이 변경될 떄 CASCADE 옵션이 적용된 자식 테이블을 갱싱할 때 반복게 코드를 사용한다.
>
> 따라서 대량의 데이터를 갱신시에 성능적 문제가 발생하지만, DBMS 내부적으로 일어나므로 사용자가 제어 또는 튜닝할 수 없다. 

## 반복계의 단점

#### 1. 성능

반복계로 구현한 코드는 **포장계(반복을 사용하지 않은)**로 구현한 코드에 성능적으로 완벽하게 진다.
레코드 수가 적을 때에는 반복계가 빠른 경우도 있지만, 레코드 수가 많아질수록 성능 차이가 더욱 벌어진다.



SQL을 실행할 때는 데이터를 검색하거나 연산하는 실제의 SQL 처리이외에도 다양한 처리가 이루어진다

> SQL 실행의 오버헤드

- 전처리
  1. SQL 구문을 네트워크로 전송
  2. 데이터베이스 연결
  3. SQL 구문 파스
  4. SQL 구문의 실행 계획 생성 / 평가
- 후처리
  1. 결과 집합을 네트워크로 전송

1번과 5번의 과정인 네트워크의 경우 내부의 동일 LAN 위에 있으므로 전송 속도 자체는 거의 밀리 sec이다. 

* -> 오버헤드가 딱히 일어나지 않음

2번 연결같은 경우 **커넥션 풀**이라는 기술을 사용해 거의 문제되지 않는다.

문제가 되는 경우는 3번 구문 파싱(구문 분석, parse)과 4번 실행계획 생성 / 평가 과정이다.

> **파스(parse, 구문 분석)는 SQL을 받을 때 마다 실행되므로 작은 SQL을 여러 번 반복하는 반복계에서는 오버헤드가 높아**질 수 밖에 없다.
>
> - SQL은 실행 시간과 관계 없이 일정한 오버헤드가 필요하다.

![image-20230210225150038](/Users/ysk/study/study_repo/postgresql/images//image-20230210225150038.png)

#### 2. 병렬 분산의 어려움

반복계는 반복 1회마다의 처리를 굉장히 단순화한다. 따라서 리소스를 분산해서 병렬 처리하는 최적화가 되지 않는다. 

데이터베이스는 대부분 **RAID 디스크**로 구성되어 I/O 부하를 분산화할 수 있게 되어있지만, **반복계에서 실행하는 SQL 구문은 너무 단순해 1회의 접근하는 데이터양이 적다.**

> 반복계는 반복 1회마다 처리가 단순하기 때문에, 리소스를 분산해 I/O를 부하를 분산하는 병렬 처리하는 최적화가 불가능하다.

![image-20230210225316038](/Users/ysk/study/study_repo/postgresql/images//image-20230210225316038.png)

#### 3. 데이터베이스 업그레이드

DBMS의 버전이 오를수록 옵티마이저는 보다 효율적으로 실행 계획을 세우며, 데이터에 고속으로 접근할 수 있는 아키텍처를 구현한다.
DB **업데이트의 중심은 대규모 데이터를 다루는 복잡한 SQL구문을 빠르게 만들기 위해**서이다.

> 반복계는 미들웨어의 진화의 혜택을 거의 받을 수 없다.

포장계(반복을 사용하지 않은)가 반복계보다 성능이 좋다는 가정은 포장계의 SQL이 충분히 튜닝되어 있다는 가정이 있어야한다.
일반적으로 굉장히 단순한 반복계의 SQL은 튜닝 가능성이 거의 없지만, 포장계의 SQL은 매우 복잡하기 때문에 튜닝의 가능성이 매우 크다. (이것은 포장계의 단점이기도 하다.-복잡하니까)

* 튜닝을 하지 않은 포장계는 반복계보다 느릴 수 있다.
* 하지만 포장계의 SQL 구문은 튜닝할 수 있으므로 제대로 한다면 반복계를 이긴다

> 반복계는 단지 느리기만 한 것이 아닌, 느린 구문을 튜닝할 수 있는 가능성이 거의 없다.
>
> 포장계의 장점은 반대로 반복계의 단점이라고 할 수 있다.



### 반복계를 빠르게 만드는 방법

반복계는 튜닝의 선택지가 한정적이다.

수백 개 정도의 요청정도는 성능이 괜찮게 나온다. 하지만 수백, 수천 개의 처리가 기본인 일괄 처리(batch)같은 경우는 절대로 사용하면 안된다. 따라서 무조건 반복계를 적대시하기보단 상황에 따라서 사용해야 한다.



**반복계를 포장계(반복을 사용하지 않은)로 수정**

이는 애플리케이션 수정을 의미한다. 하지만 실제 상황에서는 여러 이유로 불가능한 경우가 많다.



**각각의 SQL을 수정**

반복계에서 사용하는 SQL 구문을 수정하는 것인데, SQL 구문이 단순한 편이라 **튜닝의 효과를 받기 어렵다.**



**다중화 처리**

CPU 또는 디스크와 같은 리소스에 여유가 있고 처리를 나눌 키가 명확하다면, 성능을 선형에 가깝게 스케일할 수 있다.

### 반복계의 장점

반복계도 다양한 장점이 있다. 따라서 처리 방식을 선택할 때는 장점과 단점의 **트레이드오프에** 대한 신중한 고려가 필요하다.



**실행 계획의 안정성**

실행 계획이 단순하기 떄문에 실행 계획의 **변동의 위험이 거의 없다**.



**예상 처리 시간의 정밀도**

실행 계획이 단순하고 성능이 안정적인 반복계는 예상 처리 시간의 정밀도가 높다.

> <처리 시간> = <한 번의 실행 시간> x <실행 횟수>

포장계는 실행 계획에 따라 성능이 전혀 달라지므로 사전에 예상하기 힘들다.



**트랜잭션 제어의 편리성**

트랜잭션의 정밀도를 미세하게 제어할 수 있다.

만약 중간에 오류가 발생한다면 중간에 커밋을 했으므로 이어서 진행하면 된다. 하지만 포장계는 오류가 발생하면 처음부터 다시해야 한다.



## SQL에서의 반복 표현

반복문을 반복을 사용하지 않은(포장계)로 바꾸는 방법

### 포인트는 CASE 식과 윈도우 함수

SQL에서 반복을 대신하는 수단은 CASE 식과 윈도우 함수다. CASE 식은 IF-THEN-ELSE에 대응한다.

- 작년도와 매출액을 비교해 +, -, = 을 표시하는 SQL

```sql
INSERT INTO Sales2
SELECT company, year, sale,
	CASE SIGN(sale - MAX(sale)
    		OVER(PARTITION BY company
            		ORDER BY year
                    ROWS BETWEEN 1 PRECEDING
                    	AND 1 PRECEDING) )
   WHEN 0 THEN '='
   WHEN 1 THEN '+'
   WHEN -1 THEN '-'
   ELSE NULL END AS var
FROM Sales;
```

* SIGN 함수 : 음수일 경우 -1, 0일 경우 0을 반환
* ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING : 현재 레코드에서 1개 이전부터 1개 이전까지



### 반복 횟수가 정해지지 않은 경우

- 인접 리스트 모델과 재귀 쿼리

이사를 갈 때마다 필드를 추가해야 하는 경우가 있다고 가정.
제일 오래전에 주소를 찾고 싶다.
우편번호를 키로 삼아 이전 주소의 데이터를 줄줄이 연결해 놓았음.
-> 포인터 체인이라고 한다.
-> 포인터 체인을 사용하는 테이블 형식을 '인접 리스트 모델'이라고 부른다.

SQL에서 계층 구조를 찾는 방법 중 하나는 재귀 공통 테이블 식을 사용하는 방법이다.

```sql
WITH RECURSIVE Explosion (name, pcdoe, new_pcode, depth)
AS
(SELECT name, pcode, new_pcode, 1
	FROM PostalHistory
  WHERE name = 'A'
  	AND new_pcode IS NULL // 검색 시작
UNION
SELECT Child.name, Child.pcode, Child.new_pcode, depth + 1
	FROM Explosion AS Parent, PostalHistory AS Child
  WHERE Parent.pcode = Child.new_pcode
  	AND Parent.name = Child.name)

// 메인 SELECT 구문
SELECT name, pcode, new_pcode
	FROM Explosion
  WHERE depth = (SELECT MAX(depth)
  					FROM Explostion);
```

RECURSIVE =  재귀

```sql
WITH RECURSIVE [VIEWNAME]
AS
초기식
UNION
SELECT ~ FROM ~
WHERE RECURSIVE 종료 조건
```

Parent.pcode = Child.new_pcode AND Parent.name = Child.name
즉 Parent의 자식이 있는지 검사해서 있으면 depth를 +1 해준다고 생각하면 된다.
depth의 MAX를 구하면, 그곳이 가장 오래 전에 살은 곳이다.



SQL에서 계층 구조를 나타내는 방법은 크게 3가지가 있다.

1. 인접 리스트 모델
   - **RDB 탄생 전에도 쓰였던 고전적인 방식**
2. 중첩 집합 모델
   - **각 레코드의 데이터를 원(집합)으로 봄**
   - **계층 구조를 집합의 중첩 관계로 나타냄**
3. 경로 열거 모델
   - **갱신이 거의 발생하지 않은 테이블에서 사용함**



> RDB에서 고성능을 실현하고 싶다면, 절차 지향적인 바이어스를 떼어내고 자유로워질 필요가 있다.
>
> 동시에 반복계와 포장계의 장점과 단점을 고려하고, 어느 것을 채택할지 냉정하게 판단해야 한다.
>
> SQL이 가진 강력한 도구와 튜닝 방법을 활용하려면 반드시 **집합 지향**의 사고방식을 가져야한다.



# 6장 결합(Join)

여러 테이블의 데이터를 통합하려면 역정규화(반정규화)나 조인(결합)을 사용한다.

* 결합 알고리즘(조인 알고리즘)은 성능을 결정하고 SQL 전체의 성능을 좌우하는 요인이므로 매우 중요하다.

![image-20230210232331602](/Users/ysk/study/study_repo/postgresql/images//image-20230210232331602.png)

> 크로스 조인, 내부 조인, 외부 조인, 자기 조인, 등가 조인 비등가 조인, 네츄럴 조인, 셀프 조인 등이 있다.



### 크로스 결합 - CROSS JOIN

- 크로스 결합은 실무에서 거의 사용되지 않는다. - **데카르트 곱 (모든 조합)**
  - 비용이 많이 드는 비효율적인 연산이다.
  - 이러한 결과가 필요한 경우가 거의 없다.
- 크로스 결합은 수학에서 데카르트 곱이라고 불리는 연산으로, 가능한 **모든 조합**을 구하는 연산이다.



### 내부 결합 - INNER JOIN

- 내부 결합의 **'내부**'는 '**데카르트 곱의 부분 집합'**이라는 의미이다.
- 내부 결합은 처음부터 결합 대상을 최대한 축소하는 형태로 작동한다.

### 외부 결합 - OUTER JOIN

- 외부 결합의 **'외부'**는 '데카르트 곱의 부분 집합이 아니다'라는 의미다.
  - 경우에 따라서 테카르트 곱의 부분 집합이 되기도 한다.
- 조인 주인이 되는(left - left table, right - right table, full - left + right) 쪽에 존재하는 키는 모두 포함한다
- 외부 결합은 세 가지 종류가 있다
  - **왼쪽 외부 결합 - LEFT OUTER JOIN**
  - **오른쪽 외부 결합 - RIGHT OUTER JOIN**
  - **완전 내부 결합 - OUTER JOIN**

### 자기 결합 - SELF JOIN

- 자기 결합은 문자 그대로 자신과 결합하는 것이다. 따라서 앞선 세 결합과는 분류가 자체가 다르다.
- 결합 연산의 대상에 자기 자신이 있으면 자기 결합 연산이 된다.
- 논리적으로는 자기 자신과 똑같이 생긴 다른 테이블을 결합한다고 생각해도 상관 없다.

## 결합 알고리즘과 성능

옵티마이저가 선택 가능한 결합 알고리즘의 종류

- Nested Loops
- Hash
- Sort Merge

### 1. Nested Loops 알고리즘

이름 그대로 중첩 반복(2중 포문)을 사용하는 조인 알고리즘이다.

![image-20230210233027902](/Users/ysk/study/study_repo/postgresql/images//image-20230210233027902.png)

#### 세부 처리방식

1. **결합 대상 테이블(Table_A)**에서 레코드를 하나씩 반복하며 스캔한다. 
   * 이 테이블을(A 테이블) **구동 테이블(driving table)** 또는 **외부 테이블(outer_table)**이라고 한다. 
   * **다른 테이블(B 테이블)**은 **내부 테이블(inner table)**이라고 부른다.

2. 구동 테이블이 레코드를 하나마다 **내부 테이블의 레코드를 스캔**해서 **결합 조건에 맞으면 리턴**한다.
3. 2를 구동 테이블의 모든 레코드에 반복한다.

#### 특징

- **Table_A**, **Table_B**의 결합 대상 레코드를 **R(A)**, **R(B)**라고 하면 접근되는 레코드 수는 **R(A) x R(B)**가 된다.
-  **Nested Loops**의 **실행 시간**은 이러한 레코드 수에 비례한다.
- 한 번의 단계에서 처리하는 레코드 수가 적어, Hash나 Sort Merge에 비해 메모리 소비가 적다.
- 모든 DMBS에서 지원한다.

#### 구동 테이블(결합 대상 왼쪽 테이블)의 중요성

NL 결합에서 구동 테이블으로 작은 테이블을 선택하는 것이 성능 개선이 된다는 말이 있다. 하지만 이 말에는 한 가지 조건이 필요하다. 

바로 '**내부 테이블(오른쪽 테이블 B)의 결합 키 필드에 인덱스가 존재**해야 한다'는 것이다.

인덱스가 존재하면 반복없이 찾을 수 있기 때문에 반복을 생략할 수 있다 . 

민약 구동 테이블의 한 레코드에 내부 테이블의 한 레코드가 대응하고 이를 **인덱스로 찾을 수 있다면,** 

접근하는 레코드 수는 **R(A) x N(리프 노드까지의 거리)**가 된다.

> 내부 테이블(오른쪽 대상 테이블)의 반복을 완전하게 생략할 수 있는 경우는, 결합 키(key)가 내부 테이블에 대해 유일성을 띄면 반복을 완전히 생략할 수 있다. 
>
> **INDEX UNIQUE SCAN**

![image-20230210233451584](/Users/ysk/study/study_repo/postgresql/images//image-20230210233451584.png)

다만 한 레코드가 여러 레코드에 대응하는 경우 여러개의 레코드에 반복을 적용해야 한다. ( index range scan )



이상적인 경우 : 구동 테이블의 레코드 한 개에 내부 테이블의 레코드 한 개가 대응

- 내부 테이블의 인덱스를 사용해 찾을 수 있으므로 접근하는 레코드 수는
  ***Table_A \* 2***가 된다.

내부 테이블이 클수록 인덱스 사용으로 인한 반복 생략 효과가 커진다.

> '구동 테이블이 작은 Neted Loops + 내부 테이블의 결합 키에 인덱스' 조합은 SQL 튜닝의 기본 중에 기본이다.

#### Nested Loops의 단점

내부 테이블의 **결합 키가 유일하지 않고**, 여러개의 레코드를 **히트(hit)**하게 되어 선택률이 높으면 성능이 악화된다.

* 히트된 여러개의 레코드에 반복을 적용해야 하므로. 
* 이럴 때는 **INDEX RANGE SCAN** 라고 한다. 

![image-20230210233731442](/Users/ysk/study/study_repo/postgresql/images//image-20230210233731442.png)

해결 방안 :

- 구동 테이블(왼쪽) 로 큰 테이블을 선택하는 역설적인 방법
  - 내부 테이블에 대한 점포 테이블의 접근이 기본 키로 수행되므로, 항상 하나의 레코드로 접근하는 것이 보장된다.
  - **-> 큰 내부 테이블에 계속해서 접근하는 것이 아닌 보다 작은 테이블에 접근하는 것이 효율적이므로 이런 방식이 성능 저하를 막을 수 있는 것 같다.**
- 해시

>최종적으로 SQL의 성능은 처리하는 데이터양에 의존한다.*

### 2. Hash (해시) 알고리즘

![image-20230210234205056](/Users/ysk/study/study_repo/postgresql/images//image-20230210234205056.png)

입력에 대해 어느정도 유일성과 균일성을 가진 값을 출력하는 해시 함수를 이용한 알고리즘

> 두 테이블 중 **더 작은 테이블**을 **해시 테이블**로 만든다.

**해시의 처리 순서**

1. 작은 테이블을 스캔
2. 결합 키에 해시 함수를 적용해 해시값으로 반환
3. 다른 테이블(큰 테이블)을 스캔하고, 결합 키가 해시값에 존재하는지 확인

작은 테이블을 스캔하는 이유는 해시 테이블이 **워킹 메모리**에 저장되므로 **조금이라도 작은 것이 효율적**이기 때문이다!



#### 해시방식의 특징

- 결합 테이블로부터 해시 테이블을 만들어서 활용하므로, Nested Loops에 비해 메모리 소모가 크다.
  - 따라서 동시 실행성이 높은 OLTP에는 적절하지 않고, 야간 배치, BI/DWH에 사용한다.
  - **OLTP : 온라인 트랜잭션 처리(Online Transaction Processing)**
- 메모리가 부족하면 저장소를 사용하므로 지연이 일어난다.
- 출력되는 해시값은 입력값의 순서를 알지 못하므로, 등치(=) 결합에만 사용할 수 있다.

**해시가 유용한 경우**

- Nested Loops에서 적절한 구동 테이블(상대적으로 충분히 작은 테이블)이 존재하지 않는 경우
- 구동 테이블로 사용할만한 작은 테이블은 있지만, 내부 테이블에서 히트되는 레코드 수가 너무 많은 경우
- 내부 테이블에 인덱스가 존재하지 않는 경우

> Nested Loops가 효율적으로 작동하지 않는 경우에 사용할 수 있는 차선책이 해시이다.

하지만 해시는 반드시 양쪽의 테이블을 모두 읽어야 하므로 데이터 풀스캔이 사용되는 경우가 많다.
테이블의 규모가 굉장히 크다면, 풀 스캔에 걸리는 시간도 고려해야 한다.

### 3. Sort Merge 알고리즘

![image-20230210234833528](/Users/ysk/study/study_repo/postgresql/images//image-20230210234833528.png)

**Sort Merge의 작동**

Nested Loops가 비효율적인 경우 Hash 사용 외에 또다른 선택지로 SortMerge라는 알고리즘도 있다.

> SortMerges는 간단하게 Merge 또는 Merge Join이라고 부르기도 한다.

결합 대상 테이블을 각각 결합 키로 정렬하고, 일치하는 결합 키를 찾으면 결합한다.

> 1. 결합 대상 테이블을 각각 결합키로 정렬한다.
> 2. 일치하는 결합키를 찾으면 결합한다.



**Sort Merge의 특징**

- 대상 테이블을 모두 정렬하므로 Nested Loops보다 메모리 소모가 크고, 상황에 따라 Hash보다 많은 메모리를 사용한다.
- 동치 결합뿐 아니라 부등호(=, >=, <, ...)를 사용한 결합에도 사용할 수 있다.
  - 단 부정조건(<>) 결합에는 사용할 수 없다.
- 테이블이 결합키로 정렬되어 있다면 정렬이 필요 업지만, 이는 구현 의존적이다.

테이블 정렬에 많은 시간과 리소스를 요구할 가능성이 있다.

> 테이블 정렬을 생략할 수 있는 경우에는 고려해볼 만 하지만, 그 이외의 경우는 Nested Loop와 Hash를 우선적으로 고려해야 한다.



**Sort Meger가 유효한 경우**

Sort Merge은 결합 자체에 걸리는 시간은 나쁘지 않은 편이지만, 정렬에 많은 시간과 리소스를 소모할 가능성이 있으므로 테이블 정렬을 생략할 수 있는(매우 예외적인) 상황을 제외하고는 Nested Loops나 Hash를 우선적으로 고려하는게 좋다.



## 의도하지 않은 크로스 결합(Cross Join)

의도하지 않는 크로스 결합이 일어나는 경우는 대부분 작성자의 실수 때문이고, 대부분 '삼각 결합'이라 부르는 패턴에서 문제가 발생한다.

![image-20230210235409027](/Users/ysk/study/study_repo/postgresql/images//image-20230210235409027.png)

```sql
SELECT A.a, B.b, C.c
FROM Table_A A
	INNER JOIN Table_B B
		ON A.a = B.b
	INNER JOIN Table_C C
		ON A.a = C.c
```

만약 조인 조건(결합 조건)이 되는 키가 A - B, A -C에만 존재하고 B - C는 일치하지 않는다고 가정.

* 조인 조건이 일치하지 않는 B-C 를 먼저 결합하고 후 A를 결합하는 순간 결합 조건이 없으므로 크로스 조인해버린다.

> 이러한 형태의 삼각 결합에서 Table_B와 Table_C의 결합이 일어난다면, 둘 사이에는 아무런 결합조건이 없기에 크로스 결합이 일어난다.
>
> 사실 작은 테이블 사이의 크로스 결합은 자주 일어나며, 크게 두려워할 필요는 없다. 하지만 비교적 큰 테이블 끼리의 크로스 결합이 일어나는 경우는 큰 성능 저하가 일어난다.

### 의도하지 않은 크로스 결합을 회피하는 법

불필요한 결합 조건을 추가해서 크로스 결합을 회피한다

```sql
SELECT A.a, B.b, C.c
FROM Table_A A
	INNER JOIN Table_B B
		ON A.a = B.b
	INNER JOIN Table_C C
		ON A.a = C.c
		AND C.c = B.b; # 불필요한 결합 조건을 추가하여 크로스 조인을 회피
```

## 결합이 느리다면 (Join이 느리다면)

### 1. 상황에 따른 최적의 결합 알고리즘

Nested Loops, Hash ,Sort Merge 3가지의 알고리즘의 장, 단점

| 이름         | 장점                                                         | 단점                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Nested Loops | '작은 구동 테이블' + '내부 테이블의 인덱스 '라는 조건이 있다면 굉장히 빠르다.<br />메모리 또는 디스크 소비가 적으므로 내부 테이블의 선택률이 높으면 느리다. | 대규모 테이블들의 결합에는 부적합<br />내부 테이블의 인덱스가 사용되지 않거나 내부 테이블의 선택률이 높으면 느리다. |
| Hash         | 대규모 테이블들을 결합할 때 적합                             | 메모리 소비량이 큰 OLTP에는 부적합<br />메모리 부족이 일어나면 TEMP 탈락 발생<br />등가 결합에서만 사용 가능 |
| Sort Merge   | 대규모 테이블들을 결합할 때 적합<br />비등가 결합에서도 사용 가능 | 메모리 소비량이 큰 OLTP에는 부적합<br />메모리 부족이 일어나면 TEMP 탈락 발생<br />**데이터가 정렬되어 있지 않다면 비효율적** |

옵티마이저는 이런 장단점을 보면ㅅ서 알고리즘을 선택한다. 

* 하지만 옵티마이저도 완벽한 존재는 아니므로, 통계정보가 오래되어 제대로 된 정보를 검색하지 못한다면 최적의 결합알고리즘을 선택하지 못할수도 있다.



최적의 결합 알고리즘을, 결합 대상 레코드 수의 관점에서 정리하면 다음과 같

**소규모 - 소규모**

어떤 알고리즘을 사용해도 큰 차이가 없습니다.



**소규모 - 대규모**

소규모 테이블을 구동 테이블로 하는 경우 Nested Loops를 사용한다.  

하지만 내부 테이블의 결합 대상 레코드가 너무 많다면 구동 테이블과 내부 테이블을 바꾸거나, Hash를 사용하는 것을 검토해 보아라.



**대규모 - 대규모**

Hash를 사용한다. 결합키로 정렬이 되어 있다면 Sort Merge를 사용한다.

> 사용할 수 있는 메모리의 양, 또는 결합 키의 카디널리티 등 세세한 조건에 따라 최적의 방법은 바뀔 수 있다.
>
> 기본적으로는 일단 Nested Loops 잘 안되면 Hash

### 2. 실행 계획 제어

실행 계획을 바꾸는 것은 DBMS 마다 다르다.

- Oracle
  - 힌트 구로 결합 알고리즘을 제어 할 수 있다.
  - 구동 테이블도 지정할 수 있다.
- SQL Server
  - 힌트 구로 결합 알고리즘을 제어할 수 있다.
- DB2
  - 힌트 구가 없으며, 원칙적으로 실행계획을 제어할 수 없다.
- PostgreSQL
  - pg_hint_plan을 이용해 결합 알고리즘을 제어할 수 있다.
  - 서버 매개변수로 데이터베이스 전체를 제어할 수 있다.
- MySQL
  - 결합 알고리즘 자체가 Nested Loops 계열 밖에 없어서 제어의 의미가 없다.

사용자가 실행 계획을 제어하면, 실행 계획이 고정되기 때문에 비효율적일 수 있다.
그렇다고 옵티마이저의 선택이 언제나 옳지도 않다.

**조인(결합)을 피하는 방법**

- 비정규화 (뭔지 모름)
- 결합을 최소화 -> 상관 서브쿼리로 대체, 등



# 7장 서브쿼리

서브쿼리란 SQL 내부에서 작성되는 일시적인 테이블이다.
테이블과 서브쿼리는 기능적인 관점에서 차이가 없기 때문에 **SQL은 두 가지를 모두 같은 것으로 취급**한다.

- 테이블 : 영속적인 데이터를 저장
- 뷰 : 영속적이지만 데이터는 저장하지 않음. (접근할 때마다 SELECT 구문 실행)
- 서브쿼리 : 비영속적인 생존 기간(스코프)이 SQL 구문 실행 중으로 한정

> 성능적인 관점에서 보면 서브쿼리 또는 뷰는 같은 데이터를 저장하고 있는 경우라도 테이블에 비해 성능이 나쁜 경향이 있다.



## 서브쿼리의 문제점

서브쿼리의 성능적 문제는 서브쿼리가 실체적인 데이터를 저장하고있지 않다는 점을 생각하자.

#### 연산 비용 추가

- 데이터를 저장하고 있지 않아, 서브쿼리에 접근할 때마다 SELECT 구문을 실행해서 데이터를 만들어야 한다.
  - SELECT 구문 실행에 발생하는 비용이 추가
  - 서브쿼리의 내용이 복잡하면 복잡할수록 이러한 실행비용은 높아진다.

#### 데이터 I/O 비용 발생

- 연산 결과는 어딘가에 저장하기 위해 써두어야 한다.
- 데이터양이 큰 경우에는 DBMS가 저장소에 있는 파일에 결과를 쓸 때도 있다.
-  메모리가 크다면 상관 없지만 부족하다면 저장소의 파일을 사용하는 경우도 있다. 
  - 이렇게 되면 저장소 성능에 따라 접근 속도가 떨어진다.
- TEMP 탈락 현상이 발생해 접근 속도가 급격하게 떨어진다.

#### 최적화를 받을 수 없음

* 서브쿼리로 만들어지는 데이터는 테이블과 똑같은 구조를 가진다. 

* 하지만 테이블과는 달리 **명시적인 제약이나 인덱스같이 메타 정보가 없다.** 

* **따라서 옵티마이저가 쿼리를 해석하기 위해 필요한 정보를 얻을 수 없다.**

* 필요한 정보를 서브쿼리에서 얻기 위한 해결하기 위한 방법 : 뷰 병합(view merge)

**단점**

1. 서브쿼리를 사용하면 코드가 여러 계층에 걸쳐 만들어져 가독성이 떨어진다.

2. 성능

   - 서브쿼리는 대부분 일시적인 영역(메모리 or 디스크)에 확보되므로 오버헤드 발생

   - 서브쿼리는 인덱스 또는 제약 정보를 가지지 않아 최적화되지 못함

   - 이 쿼리는 결합을 필요로 하기 때문에 비용이 높고 실행 계획 변동 리스크가 발생

   - Receipts 테이블에 스캔이 두 번 발생

### 장기적인 리스크 관리

결합을 사용한 쿼리는 다음과 같은 불안정 요소를 가진다.

- 결합 알고리즘의 변동 리스크
- 환경 요인에 의한 지원 리스크(인덱스, 메모리, 매개변수, ...)

따라서 결합을 사용한다면 이러한 리스크를 안아야 한다. 그러므로 가능하다면 결합을 사용하지 않는 쿼리를 작성하는게 리스크를 줄일 수 있다.



## 서브쿼리 사용이 더 나은 경우

서브쿼리 사용이 성능 측면에서 더 나은 경우는 결합(조인)을 사용 할 때다.

결합을 사용할 때는 최대한 결합 대상 레코드를 줄여야 한다. 

그런데 옵티마이저가 이러한 것을 잘 판별하지 못할 때는 서브쿼리를 사용해 명시적으로 처리해 주는것이 좋다.



# 8장 SQL의 순서



# 9장 갱신과 데이터 모델



# 10장 인덱스 사용